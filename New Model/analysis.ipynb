{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "api_url = \"https://debt-api-4301881a2ff8.herokuapp.com/loan/get_all\"\n",
    "res = requests.get(api_url)\n",
    "data = pd.DataFrame(res.json()[\"data\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>married</th>\n",
       "      <th>dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>applicantIncome</th>\n",
       "      <th>coapplicant_income</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_amount_term</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>property_area</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loan_id gender married dependents     education self_employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   applicantIncome coapplicant_income  loan_amount  loan_amount_term  \\\n",
       "0             5849                  0          NaN             360.0   \n",
       "1             4583               1508        128.0             360.0   \n",
       "2             3000                  0         66.0             360.0   \n",
       "3             2583               2358        120.0             360.0   \n",
       "4             6000                  0        141.0             360.0   \n",
       "\n",
       "   credit_history property_area loan_status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (data[((data['ApplicantIncome'] + data['CoapplicantIncome']) * data['Loan_Amount_Term'] < data['LoanAmount']) & (data['Loan_Status'] == 'Y')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = {\n",
    "    'KNNClassifier': 'KNNClassifier',\n",
    "    'LogisticRegression': 'LogisticRegression',\n",
    "    'NaiveBayes': 'NaiveBayes',\n",
    "    'RandomForestClassifier': 'RandomForestClassifier',\n",
    "    'RandomForestRegressor': 'RandomForestRegressor',\n",
    "    'SupportVectorClassifier': 'SupportVectorClassifier',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = {\n",
    "            # classification_models['DecisionTreeClassifier']: 'files/pkl_2/DecisionTreeClassifier.pkl',\n",
    "            # classification_models['KNNClassifier']: './../../files/pkl/KNNClassifier.pkl',\n",
    "            # classification_models['LogisticRegression']: './../../files/pkl/LogisticRegression.pkl',\n",
    "            # classification_models['NaiveBayes']: './../../files/pkl/NaiveBayes.pkl',\n",
    "            classification_models['RandomForestClassifier']: './random_forest_model.pkl',\n",
    "            # classification_models['SupportVectorClassifier']: './../../files/pkl/SupportVectorClassifier.pkl',\n",
    "            # classification_models['RandomForestRegressor']: './../../files/pkl/RandomForestRegressor.pkl',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open(model_files['RandomForestClassifier'] , 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kNNClassifier = pickle.load(open(model_files['KNNClassifier'] , 'rb'))\n",
    "logisticRegression = pickle.load(open(model_files['LogisticRegression'] , 'rb'))\n",
    "naiveBayes = pickle.load(open(model_files['NaiveBayes'] , 'rb'))\n",
    "randomForestClassifier = pickle.load(open(model_files['RandomForestClassifier'] , 'rb'))\n",
    "supportVectorClassifier = pickle.load(open(model_files['SupportVectorClassifier'] , 'rb'))\n",
    "randomForestRegressor = pickle.load(open(model_files['RandomForestRegressor'] , 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_SupportVectorClassifier =  pickle.load(open(model_files['SupportVectorClassifier'] , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    result_KNNClassifier = _KNNClassifier.predict(test_input)\n",
    "    result_LogisticRegression = _LogisticRegression.predict(test_input)\n",
    "    result_NaiveBayes = _NaiveBayes.predict(test_input)\n",
    "    result_RandomForestClassifier = _RandomForestClassifier.predict(test_input)\n",
    "    result_SupportVectorClassifier = _SupportVectorClassifier.predict(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dependents\n- education\n- gender\n- married\n- property_area\n- ...\nFeature names seen at fit time, yet now missing:\n- dependents_0\n- dependents_1\n- dependents_2\n- dependents_3+\n- education_Graduate\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 57\u001b[0m\n\u001b[1;32m     25\u001b[0m test_input \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarried\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarried\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_area\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_area\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     37\u001b[0m }, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# test_input['gender'] = le_gender.fit_transform(\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#     test_input['gender'])\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# test_input['married'] = le_married.fit_transform(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# result_SupportVectorClassifier = le_loan_status.inverse_transform(supportVectorClassifier.predict(test_input))[0]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# result_RandomForestRegressor= le_loan_status.inverse_transform(randomForestRegressor.predict(test_input))[0]\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_status\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(row['loan_id'],result_KNNClassifier, result_LogisticRegression, result_NaiveBayes, result_RandomForestClassifier, result_SupportVectorClassifier, row['loan_status'])\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/projects/sust/Debt-Prediction-Model-and-API/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/projects/sust/Debt-Prediction-Model-and-API/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/Desktop/projects/sust/Debt-Prediction-Model-and-API/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/projects/sust/Debt-Prediction-Model-and-API/venv/lib/python3.11/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/projects/sust/Debt-Prediction-Model-and-API/venv/lib/python3.11/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dependents\n- education\n- gender\n- married\n- property_area\n- ...\nFeature names seen at fit time, yet now missing:\n- dependents_0\n- dependents_1\n- dependents_2\n- dependents_3+\n- education_Graduate\n- ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isnull(row['gender']):\n",
    "        row['gender'] = 'Male'\n",
    "    if pd.isnull(row['married']):\n",
    "        row['married'] = 'No'\n",
    "    if pd.isnull(row['dependents']):\n",
    "        row['dependents'] = 0\n",
    "    if pd.isnull(row['education']):\n",
    "        row['education'] = 'Not Graduate'\n",
    "    if pd.isnull(row['self_employed']):\n",
    "        row['self_employed'] = 'No'\n",
    "    if pd.isnull(row['applicantIncome']):\n",
    "        row['applicantIncome'] = 0\n",
    "    if pd.isnull(row['coapplicant_income']):\n",
    "        row['coapplicant_income'] = 0\n",
    "    if pd.isnull(row['loan_amount']):\n",
    "        row['loan_amount'] = 0\n",
    "    if pd.isnull(row['loan_amount_term']):\n",
    "        row['loan_amount_term'] = 0\n",
    "    if pd.isnull(row['credit_history']):\n",
    "        row['credit_history'] = 0\n",
    "    if pd.isnull(row['property_area']):\n",
    "        row['property_area'] = 'Rural'\n",
    "\n",
    "    test_input = pd.DataFrame({\n",
    "        'gender': row['gender'],\n",
    "        'married': row['married'],\n",
    "        'dependents': row['dependents'],\n",
    "        'education': row['education'],\n",
    "        'self_employed': row['self_employed'],\n",
    "        'applicantIncome': row['applicantIncome'],\n",
    "        'coapplicant_income': row['coapplicant_income'],\n",
    "        'loan_amount': row['loan_amount'],\n",
    "        'loan_amount_term': row['loan_amount_term'],\n",
    "        'credit_history': row['credit_history'],\n",
    "        'property_area': row['property_area']\n",
    "    }, index=[0])\n",
    "\n",
    "    # test_input['gender'] = le_gender.fit_transform(\n",
    "    #     test_input['gender'])\n",
    "    # test_input['married'] = le_married.fit_transform(\n",
    "    #     test_input['married'])\n",
    "    # test_input['education'] = le_education.fit_transform(\n",
    "    #     test_input['education'])\n",
    "    # test_input['self_employed'] = le_self_employed.fit_transform(\n",
    "    #     test_input['self_employed'])\n",
    "    # test_input['property_area'] = le_property_area.fit_transform(\n",
    "    #     test_input['property_area'])\n",
    "\n",
    "\n",
    "    # result_KNNClassifier = le_loan_status.inverse_transform(kNNClassifier.predict(test_input))[0]\n",
    "    # result_LogisticRegression = le_loan_status.inverse_transform(logisticRegression.predict(test_input))[0]\n",
    "    # result_NaiveBayes = le_loan_status.inverse_transform(naiveBayes.predict(test_input))[0]\n",
    "    # result_RandomForestClassifier = le_loan_status.inverse_transform(randomForestClassifier.predict(test_input))[0]\n",
    "    # result_SupportVectorClassifier = le_loan_status.inverse_transform(supportVectorClassifier.predict(test_input))[0]\n",
    "    # result_RandomForestRegressor= le_loan_status.inverse_transform(randomForestRegressor.predict(test_input))[0]\n",
    "    print(loaded_model.predict(test_input)[0], row['loan_status'])\n",
    "    # print(row['loan_id'],result_KNNClassifier, result_LogisticRegression, result_NaiveBayes, result_RandomForestClassifier, result_SupportVectorClassifier, row['loan_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y N\n",
      "Y N\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y N\n",
      "Y Y\n",
      "N Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y N\n",
      "N N\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "N Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N Y\n",
      "Y Y\n",
      "N N\n",
      "Y N\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y N\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "Y Y\n",
      "N N\n"
     ]
    }
   ],
   "source": [
    "# sayed bhai\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isnull(row['gender']):\n",
    "        row['gender'] = 'Male'\n",
    "    if pd.isnull(row['married']):\n",
    "        row['married'] = 'No'\n",
    "    if pd.isnull(row['dependents']):\n",
    "        row['dependents'] = 0\n",
    "    if pd.isnull(row['education']):\n",
    "        row['education'] = 'Not Graduate'\n",
    "    if pd.isnull(row['self_employed']):\n",
    "        row['self_employed'] = 'No'\n",
    "    if pd.isnull(row['applicantIncome']):\n",
    "        row['applicantIncome'] = 0\n",
    "    if pd.isnull(row['coapplicant_income']):\n",
    "        row['coapplicant_income'] = 0\n",
    "    if pd.isnull(row['loan_amount']):\n",
    "        row['loan_amount'] = 0\n",
    "    if pd.isnull(row['loan_amount_term']):\n",
    "        row['loan_amount_term'] = 0\n",
    "    if pd.isnull(row['credit_history']):\n",
    "        row['credit_history'] = 0\n",
    "    if pd.isnull(row['property_area']):\n",
    "        row['property_area'] = 'Rural'\n",
    "\n",
    "    input_data_df = pd.DataFrame([row])\n",
    "    input_data_df = pd.get_dummies(input_data_df, columns=['gender', 'married', 'dependents', 'education', 'self_employed', 'property_area'])\n",
    "\n",
    "    input_data_df = input_data_df.reindex(columns=loaded_model.feature_names_in_, fill_value=0)\n",
    "\n",
    "    print(loaded_model.predict(input_data_df)[0], row['loan_status'])\n",
    "    # print(row['loan_id'],result_KNNClassifier, result_LogisticRegression, result_NaiveBayes, result_RandomForestClassifier, result_SupportVectorClassifier, row['loan_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
